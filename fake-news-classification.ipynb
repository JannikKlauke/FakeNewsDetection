{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:36:41.529404Z",
     "start_time": "2019-10-25T15:36:40.714542Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:36:41.533854Z",
     "start_time": "2019-10-25T15:36:41.531252Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 5000\n",
    "MAX_NUM_WORDS = 25000\n",
    "EMBEDDING_DIM = 300\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "TEXT_DATA = 'data/fake_or_real_news.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:36:42.693017Z",
     "start_time": "2019-10-25T15:36:41.876397Z"
    }
   },
   "outputs": [],
   "source": [
    "# define a function that allows us to evaluate our models\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(predict_fun, X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    evaluate the model, both training and testing errors are reported\n",
    "    '''\n",
    "    # training error\n",
    "    y_predict_train = predict_fun(X_train)\n",
    "    train_acc = accuracy_score(y_train,y_predict_train)\n",
    "    \n",
    "    # testing error\n",
    "    y_predict_test = predict_fun(X_test)\n",
    "    test_acc = accuracy_score(y_test,y_predict_test)\n",
    "    \n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:36:43.623984Z",
     "start_time": "2019-10-25T15:36:43.620065Z"
    }
   },
   "outputs": [],
   "source": [
    "# estimate 95% confidence interval on error\n",
    "\n",
    "# NOTE: based on conversation on stackexchange: \n",
    "# https://stats.stackexchange.com/questions/247551/how-to-determine-the-confidence-of-a-neural-network-prediction\n",
    "# towards bottom of the page.\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "def error_conf(error, n):\n",
    "    term = 1.96*sqrt((error*(1-error))/n)\n",
    "    lb = error - term\n",
    "    ub = error + term\n",
    "    \n",
    "    return lb, ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:36:44.938227Z",
     "start_time": "2019-10-25T15:36:44.701005Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in our data and preprocess it\n",
    "\n",
    "df = pd.read_csv(TEXT_DATA)\n",
    "df.drop(labels=['id','title'], axis='columns', inplace=True)\n",
    "# only select stories with lengths gt 0 -- there are some texts with len = 0\n",
    "mask = list(df['text'].apply(lambda x: len(x) > 0))\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:36:45.104495Z",
     "start_time": "2019-10-25T15:36:45.100705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6335 texts.\n"
     ]
    }
   ],
   "source": [
    "# prepare text samples and their labels\n",
    "\n",
    "texts = df['text']\n",
    "labels = df['label']\n",
    "\n",
    "print('Found %s texts.' %texts.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:36:46.369151Z",
     "start_time": "2019-10-25T15:36:45.925079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of article lengths in terms of word counts\n",
    "\n",
    "text_lengths = texts.apply(lambda x: len(x.split(\" \")))\n",
    "plt.hist(text_lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:36:52.789961Z",
     "start_time": "2019-10-25T15:36:49.108760Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up vector models for training and testing\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# data vectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", \n",
    "                             binary = True, \n",
    "                             min_df = 2,\n",
    "                             stop_words='english')\n",
    "docarray = vectorizer.fit_transform(texts).toarray()\n",
    "docterm = pd.DataFrame(docarray, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:36:54.192613Z",
     "start_time": "2019-10-25T15:36:52.791851Z"
    }
   },
   "outputs": [],
   "source": [
    "# create training and test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "docterm_train, docterm_test, y_train, y_test = train_test_split(docterm, labels, test_size=TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:36:55.841846Z",
     "start_time": "2019-10-25T15:36:54.194754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(docterm_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:36:57.159950Z",
     "start_time": "2019-10-25T15:36:55.843967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 93.94%\n",
      "Testing Accuracy: 89.98%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "\n",
    "train_acc, test_acc = evaluate_model(model.predict, docterm_train, y_train, docterm_test, y_test)\n",
    "print(\"Training Accuracy: {:.2f}%\".format(train_acc*100))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:36:57.166898Z",
     "start_time": "2019-10-25T15:36:57.161894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval: 88.32%-91.63%\n"
     ]
    }
   ],
   "source": [
    "# estimate 95% confidence interval\n",
    "\n",
    "n = docterm_test.shape[0]\n",
    "lb, ub = error_conf(1-test_acc, n)\n",
    "\n",
    "print(\"95% confidence interval: {:.2f}%-{:.2f}%\".format((1-ub)*100,(1-lb)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBM and Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T17:59:12.557084Z",
     "start_time": "2019-10-25T15:48:25.856375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -1848.30, time = 143.70s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -9518.09, time = 160.47s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -6232.56, time = 156.87s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -3698.62, time = 156.60s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1408.05, time = 157.43s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -3551.15, time = 156.60s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -11297.64, time = 155.76s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -3092.05, time = 156.41s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -3222.33, time = 157.14s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -2820.80, time = 156.69s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -3746.24, time = 157.12s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -20509.61, time = 156.80s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -1817.61, time = 157.17s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -2887.42, time = 156.53s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -2853.69, time = 156.05s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -5193.21, time = 156.32s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -3399.26, time = 155.87s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -2456.06, time = 156.69s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -2249.84, time = 156.39s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -2683.17, time = 156.63s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -3096.01, time = 156.74s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -6021.65, time = 156.40s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -4101.04, time = 153.69s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -6350.88, time = 154.58s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -2870.80, time = 153.20s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -3163.31, time = 152.83s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -2986.00, time = 152.91s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -4336.75, time = 153.52s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -2610.11, time = 154.53s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -2209.65, time = 154.86s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -2624.28, time = 154.67s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -1859.65, time = 154.55s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -2666.16, time = 154.65s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -2291.22, time = 154.85s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -1373.40, time = 155.09s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -1820.41, time = 153.90s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -2384.09, time = 152.14s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -2254.46, time = 153.78s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -1616.27, time = 152.15s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -1789.90, time = 152.48s\n",
      "[BernoulliRBM] Iteration 41, pseudo-likelihood = -3141.92, time = 155.46s\n",
      "[BernoulliRBM] Iteration 42, pseudo-likelihood = -2139.75, time = 161.33s\n",
      "[BernoulliRBM] Iteration 43, pseudo-likelihood = -3309.65, time = 163.08s\n",
      "[BernoulliRBM] Iteration 44, pseudo-likelihood = -4550.04, time = 164.75s\n",
      "[BernoulliRBM] Iteration 45, pseudo-likelihood = -1856.87, time = 163.79s\n",
      "[BernoulliRBM] Iteration 46, pseudo-likelihood = -3433.36, time = 161.92s\n",
      "[BernoulliRBM] Iteration 47, pseudo-likelihood = -1786.85, time = 163.01s\n",
      "[BernoulliRBM] Iteration 48, pseudo-likelihood = -1893.52, time = 154.69s\n",
      "[BernoulliRBM] Iteration 49, pseudo-likelihood = -2124.77, time = 153.90s\n",
      "[BernoulliRBM] Iteration 50, pseudo-likelihood = -1505.85, time = 154.05s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('rbm',\n",
       "                 BernoulliRBM(batch_size=256, learning_rate=0.03,\n",
       "                              n_components=4000, n_iter=50, random_state=None,\n",
       "                              verbose=1)),\n",
       "                ('Naive Bayes',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "\n",
    "rbm= BernoulliRBM(random_state=0, verbose=True)\n",
    "#RBM params\n",
    "learning_rate = 0.03 # from Erhan et el. (2010): median value in grid-search\n",
    "total_units   =  4000 \n",
    "total_epochs  =   50 # from Erhan et el. (2010): optimal for MNIST\n",
    "batch_size    =  256 # seems like a representative sample; backprop literature often uses 256 or 512 samples\n",
    "\n",
    "rbm = BernoulliRBM(n_components=total_units, learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs, verbose=1)\n",
    "\n",
    "classifier = Pipeline(steps=[('rbm', rbm), ('Naive Bayes', model)])\n",
    "classifier.fit(docterm_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old performance with only 1 epoch of Training with 5000 units of RBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:46:48.398739Z",
     "start_time": "2019-10-25T15:46:30.046991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 65.35%\n",
      "Testing Accuracy: 63.77%\n"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = evaluate_model(classifier.predict, docterm_train, y_train, docterm_test, y_test)\n",
    "print(\"Training Accuracy: {:.2f}%\".format(train_acc*100))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New performance with 50 epochs of training with 4000 units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T17:59:42.495957Z",
     "start_time": "2019-10-25T17:59:28.906305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 75.06%\n",
      "Testing Accuracy: 73.24%\n"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = evaluate_model(classifier.predict, docterm_train, y_train, docterm_test, y_test)\n",
    "print(\"Training Accuracy: {:.2f}%\".format(train_acc*100))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:06:48.708062Z",
     "start_time": "2019-10-25T18:06:43.843099Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save RBM:\n",
    "import pickle\n",
    "\n",
    "rbm_1 = classifier[0]\n",
    "with open(\"RBM_4000unit_50ep_003learn.mdl\", \"wb\") as handle:\n",
    "    pickle.dump(rbm_1, handle)\n",
    "\n",
    "#test:\n",
    "\n",
    "with open(\"RBM_4000unit_50ep_003learn.mdl\", \"rb\") as handle:\n",
    "    rbm_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:10:12.872610Z",
     "start_time": "2019-10-25T18:10:10.334569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 73.24%\n",
      "Testing Accuracy: 73.24%\n"
     ]
    }
   ],
   "source": [
    "#test1 (with saved model)\n",
    "test_transformed_1 = rbm_1.transform(docterm_test)\n",
    "train_acc, test_acc = evaluate_model(classifier[1].predict, test_transformed_1, y_test, test_transformed_1, y_test)\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:11:23.818404Z",
     "start_time": "2019-10-25T18:11:20.661647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 73.24%\n",
      "Testing Accuracy: 73.24%\n"
     ]
    }
   ],
   "source": [
    "# test 2 (with loaded model)\n",
    "test_transformed_2 = rbm_test.transform(docterm_test)\n",
    "train_acc, test_acc = evaluate_model(classifier[1].predict, test_transformed_2, y_test, test_transformed_1, y_test)\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Sigmoid NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:42:48.074425Z",
     "start_time": "2019-10-25T18:42:48.070658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5068, 39271)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docterm_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:47:10.638533Z",
     "start_time": "2019-10-25T18:47:10.633960Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:47:53.735026Z",
     "start_time": "2019-10-25T18:47:53.727901Z"
    }
   },
   "outputs": [],
   "source": [
    "# build a simple Softmax/Sigmoid Classifier                                                                   \n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "np.random.seed(1337)\n",
    "nb_classes = 2\n",
    "batch_size = 128\n",
    "nb_epochs = 10\n",
    "\n",
    "y_train_2d = np_utils.to_categorical(y_train.apply(lambda x: 0 if x == \"FAKE\" else 1), 2)\n",
    "y_test_2d = np_utils.to_categorical(y_test.apply(lambda x: 0 if x == \"FAKE\" else 1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:47:19.606139Z",
     "start_time": "2019-10-25T18:47:19.601452Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:47:59.754803Z",
     "start_time": "2019-10-25T18:47:59.656222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 100)               3927200   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 3,928,232\n",
      "Trainable params: 3,928,232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape =(39271,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:49:57.956884Z",
     "start_time": "2019-10-25T18:49:17.833924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5068 samples, validate on 1267 samples\n",
      "Epoch 1/10\n",
      "5068/5068 [==============================] - 5s 1ms/step - loss: 0.3680 - val_loss: 0.2051\n",
      "Epoch 2/10\n",
      "5068/5068 [==============================] - 4s 742us/step - loss: 0.0687 - val_loss: 0.1832\n",
      "Epoch 3/10\n",
      "5068/5068 [==============================] - 4s 732us/step - loss: 0.0273 - val_loss: 0.2024\n",
      "Epoch 4/10\n",
      "5068/5068 [==============================] - 4s 739us/step - loss: 0.0151 - val_loss: 0.2222\n",
      "Epoch 5/10\n",
      "5068/5068 [==============================] - 4s 767us/step - loss: 0.0091 - val_loss: 0.2464\n",
      "Epoch 6/10\n",
      "5068/5068 [==============================] - 4s 782us/step - loss: 0.0062 - val_loss: 0.2713\n",
      "Epoch 7/10\n",
      "5068/5068 [==============================] - 4s 780us/step - loss: 0.0044 - val_loss: 0.2950\n",
      "Epoch 8/10\n",
      "5068/5068 [==============================] - 4s 739us/step - loss: 0.0034 - val_loss: 0.3110\n",
      "Epoch 9/10\n",
      "5068/5068 [==============================] - 4s 739us/step - loss: 0.0026 - val_loss: 0.3482\n",
      "Epoch 10/10\n",
      "5068/5068 [==============================] - 4s 749us/step - loss: 0.0021 - val_loss: 0.3468\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "history = model.fit(docterm_train.values, \n",
    "                    y_train_2d,\n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    validation_data=(docterm_test.values, y_test_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:50:01.518606Z",
     "start_time": "2019-10-25T18:50:01.502154Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:53:27.596158Z",
     "start_time": "2019-10-25T18:53:25.400213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999802683504341\n",
      "0.9321231254932912\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "\n",
    "Y_train_predclass = model.predict_classes(docterm_train,batch_size=batch_size)\n",
    "Y_test_predclass = model.predict_classes(docterm_test,batch_size=batch_size)\n",
    "\n",
    "print(accuracy_score(y_train.apply(lambda x: 0 if x == \"FAKE\" else 1), Y_train_predclass))\n",
    "print(accuracy_score(y_test.apply(lambda x: 0 if x == \"FAKE\" else 1), Y_test_predclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:54:37.349893Z",
     "start_time": "2019-10-25T18:54:37.346254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval: 91.83%-94.60%\n"
     ]
    }
   ],
   "source": [
    "# estimate 95% confidence interval\n",
    "\n",
    "n = docterm_test.shape[0]\n",
    "lb, ub = error_conf(1-0.9321231254932912, n)\n",
    "\n",
    "print(\"95% confidence interval: {:.2f}%-{:.2f}%\".format((1-ub)*100,(1-lb)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline RBM and Sigmoid Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T19:00:31.510116Z",
     "start_time": "2019-10-25T19:00:31.504892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Wrap Classifier in Keras function\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_keras_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape =(39271,)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\")\n",
    "    return model\n",
    "\n",
    "keras_clf = KerasClassifier(build_fn=create_keras_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T19:07:59.666320Z",
     "start_time": "2019-10-25T19:07:59.600767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 100)               400100    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 401,132\n",
      "Trainable params: 401,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(100, input_shape =(4000,)))\n",
    "model2.add(Activation(\"relu\"))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation(\"relu\"))\n",
    "model2.add(Dense(nb_classes))\n",
    "model2.add(Activation(\"softmax\"))\n",
    "model2.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\")\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T19:08:35.709168Z",
     "start_time": "2019-10-25T19:08:20.658022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5068 samples, validate on 1267 samples\n",
      "Epoch 1/10\n",
      "5068/5068 [==============================] - 1s 105us/step - loss: 0.7327 - val_loss: 0.6336\n",
      "Epoch 2/10\n",
      "5068/5068 [==============================] - 0s 75us/step - loss: 0.6077 - val_loss: 0.5514\n",
      "Epoch 3/10\n",
      "5068/5068 [==============================] - 0s 74us/step - loss: 0.5143 - val_loss: 0.4084\n",
      "Epoch 4/10\n",
      "5068/5068 [==============================] - 0s 74us/step - loss: 0.4143 - val_loss: 0.3783\n",
      "Epoch 5/10\n",
      "5068/5068 [==============================] - 0s 74us/step - loss: 0.3810 - val_loss: 0.4060\n",
      "Epoch 6/10\n",
      "5068/5068 [==============================] - 0s 74us/step - loss: 0.3734 - val_loss: 0.3994\n",
      "Epoch 7/10\n",
      "5068/5068 [==============================] - 0s 75us/step - loss: 0.3455 - val_loss: 0.3773\n",
      "Epoch 8/10\n",
      "5068/5068 [==============================] - 0s 75us/step - loss: 0.3352 - val_loss: 0.3672\n",
      "Epoch 9/10\n",
      "5068/5068 [==============================] - 0s 77us/step - loss: 0.3476 - val_loss: 0.3496\n",
      "Epoch 10/10\n",
      "5068/5068 [==============================] - 0s 88us/step - loss: 0.3356 - val_loss: 0.3427\n"
     ]
    }
   ],
   "source": [
    "transformed_train = rbm_test.transform(docterm_train)\n",
    "history_2 = model2.fit(transformed_train, \n",
    "                    y_train_2d,\n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    validation_data=(test_transformed_2, y_test_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T19:09:42.784310Z",
     "start_time": "2019-10-25T19:09:42.423993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8516179952644041\n",
      "0.846093133385951\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "\n",
    "Y_train_predclass = model2.predict_classes(transformed_train,batch_size=batch_size)\n",
    "Y_test_predclass = model2.predict_classes(test_transformed_2,batch_size=batch_size)\n",
    "\n",
    "print(accuracy_score(y_train.apply(lambda x: 0 if x == \"FAKE\" else 1), Y_train_predclass))\n",
    "print(accuracy_score(y_test.apply(lambda x: 0 if x == \"FAKE\" else 1), Y_test_predclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T19:43:45.574834Z",
     "start_time": "2019-10-25T19:43:45.544834Z"
    }
   },
   "outputs": [],
   "source": [
    "# DBN Architecture\n",
    "\n",
    "learning_rate = 0.03 # from Erhan et el. (2010): median value in grid-search\n",
    "batch_size    =  256  # seems like a representative sample; backprop literature often uses 256 or 512 samples\n",
    "\n",
    "# RBM 1\n",
    "\n",
    "total_units_1   =  26000 \n",
    "total_epochs_1  =   65\n",
    "\n",
    "# RBM 2\n",
    "total_units_2 = 18000\n",
    "total_epochs_2 = 50\n",
    "\n",
    "# RBM 3\n",
    "total_units_3 = 14000\n",
    "total_epochs_3 = 45\n",
    "\n",
    "# RBM 4\n",
    "total_units_4 = 9000\n",
    "total_epochs_4 = 40\n",
    "\n",
    "# RBM 5\n",
    "total_units_5 = 6000\n",
    "total_epochs_5 = 40\n",
    "\n",
    "# RBM 6\n",
    "total_units_6   =  4000 \n",
    "total_epochs_6  =   35 \n",
    "\n",
    "rbm_1 = BernoulliRBM(n_components=total_units_1, learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs_1, verbose=1)\n",
    "rbm_2 = BernoulliRBM(n_components=total_units_2, learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs_2, verbose=1)\n",
    "rbm_3 = BernoulliRBM(n_components=total_units_3, learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs_3, verbose=1)\n",
    "rbm_4 = BernoulliRBM(n_components=total_units_4, learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs_4, verbose=1)\n",
    "rbm_5 = BernoulliRBM(n_components=total_units_5, learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs_5, verbose=1)\n",
    "rbm_6 = BernoulliRBM(n_components=total_units_6, learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs_6, verbose=1)\n",
    "\n",
    "DBN = Pipeline(steps=[('rbm_1', rbm_1), ('rbm_2', rbm_2), ('rbm_3', rbm_3), ('rbm_4', rbm_4), ('rbm_5', rbm_5), ('rbm_6', rbm_6)], verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T19:43:50.698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -15881.58, time = 3112.96s\n"
     ]
    }
   ],
   "source": [
    "# Fitting DBN\n",
    "DBN.fit(docterm_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T19:43:36.948405Z",
     "start_time": "2019-10-25T19:38:07.100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Save DBN\n",
    "with open(\"DBN_26to4_6rbm.mdl\", \"wb\") as handle:\n",
    "    pickle.dump(DBN, handle)\n",
    "    \n",
    "#Save first rbm\n",
    "with open(\"RBM_26_65epoch_1dbn.mdl\", \"wb\") as handle:\n",
    "    pickle.dump(DBN[0], handle)\n",
    "    \n",
    "#Save second rbm\n",
    "with open(\"RBM_18_50epoch_2dbn.mdl\", \"wb\") as handle:\n",
    "    pickle.dump(DBN[1], handle)\n",
    "\n",
    "#Save third rbm\n",
    "with open(\"RBM_14_45epoch_3dbn.mdl\", \"wb\") as handle:\n",
    "    pickle.dump(DBN[2], handle)\n",
    "\n",
    "#Save fourth rbm\n",
    "with open(\"RBM_9_40epoch_4dbn.mdl\", \"wb\") as handle:\n",
    "    pickle.dump(DBN[3], handle)\n",
    "\n",
    "#Save fifth rbm\n",
    "with open(\"RBM_6_40epoch_5dbn.mdl\", \"wb\") as handle:\n",
    "    pickle.dump(DBN[4], handle)\n",
    "\n",
    "#Save sixth rbm\n",
    "with open(\"RBM_4_35epoch_6dbn.mdl\", \"wb\") as handle:\n",
    "    pickle.dump(DBN[5], handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline DBN and Sigmoid Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
